{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The feature names are not stored in the csv so i created a list of the features  \n",
    "headers = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\", \"class\"]\n",
    "df = pd.read_csv(\"adult.data\", sep=\",\", names = headers, index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The categorical variables will cause issues with various methods as they cannot accept string values\n",
    "# to remedy this I used one hot encoding to turn them into multiple binary variables\n",
    "# I created a list of the categorical variables to do this\n",
    "categorical_vars = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"]\n",
    "one_hot_encoding = pd.get_dummies(df[categorical_vars])\n",
    "\n",
    "# adding the one hot encoding variables to the original data frame \n",
    "# and dropping the original categorical variables\n",
    "df = pd.concat([df, one_hot_encoding], axis = 'columns')\n",
    "df = df.drop(categorical_vars, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Dependent/Independent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"class\"]\n",
    "#class is set up as a categorical varaible with values of <=50K and >50K\n",
    "# I addressed his by assingning a 1 for >50K and a 0 for <=50K\n",
    "#used a temp dataframe with binary variables for >50K and <=50K\n",
    "# pulled out the >50K column as the dependent variable\n",
    "temp = pd.get_dummies(y)\n",
    "y = temp[\" >50K\"]\n",
    "#Setting the attributes by dropping the class variable\n",
    "X = df.drop(\"class\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensamble with Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using decision tree, random forest, and SVM\n",
    "tree_clf_hard = DecisionTreeClassifier()\n",
    "rnd_clf_hard = RandomForestClassifier(n_estimators=100)\n",
    "svm_clf_hard= SVC(gamma='scale')\n",
    "voting_clf_hard = VotingClassifier(\n",
    "    estimators=[('tree', tree_clf_hard),('rf', rnd_clf_hard), ('svc', svm_clf_hard)],\n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8492678781441446\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model using 10-fold CV with the scoring as accuracy\n",
    "result1 = model_selection.cross_val_score(voting_clf_hard, X, y, cv=10, scoring='accuracy')\n",
    "print(\"accuracy:\",result1.mean())\n",
    "# the accuracy here is 0.849"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensamble with Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Decision tree, random forest, and SVM\n",
    "tree_clf_soft = DecisionTreeClassifier()\n",
    "rnd_clf_soft = RandomForestClassifier(n_estimators=100)\n",
    "svm_clf_soft = SVC(gamma='scale', probability=True)\n",
    "voting_clf_soft = VotingClassifier(\n",
    "    estimators=[('tree', tree_clf_soft), ('rf', rnd_clf_soft), ('svc', svm_clf_soft)],\n",
    "    voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8412212611053569\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model using 10-fold CV with the scoring as accuracy\n",
    "result2 = model_selection.cross_val_score(voting_clf_soft, X, y, cv=10, scoring='accuracy')\n",
    "print(\"accuracy:\",result2.mean())\n",
    "# The accuracy here is 0.841 so slighty lower than hard voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8572835186206387\n"
     ]
    }
   ],
   "source": [
    "# 100 classifiers and 500 instances using all features \n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=100,\n",
    "    max_samples=500, bootstrap=True, n_jobs=-1)\n",
    "#Evaluating the model using 10-fold CV with the scoring as accuracy\n",
    "result3 = model_selection.cross_val_score(bag_clf, X, y, cv=10, scoring=\"accuracy\")\n",
    "print(\"Accuracy:\", result3.mean())\n",
    "#accuracy here is 0.857 which is higher than both hard and soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7591904489970196\n"
     ]
    }
   ],
   "source": [
    "#Bagging with 100 classifiers and 500 instances using max_features = 5\n",
    "bag_clf1 = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=100,\n",
    "    max_samples=500, bootstrap=True, n_jobs=-1, max_features = 5)\n",
    "#Evaluating the model using 10-fold CV with the scoring as accuracy\n",
    "result4 = model_selection.cross_val_score(bag_clf1, X, y, cv=10, scoring=\"accuracy\")\n",
    "print(\"Accuracy:\", result4.mean())\n",
    "#accuracy here is 0.759 which is about .1 lower than with no limit with max_features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First changing values for learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8609381306111427\n"
     ]
    }
   ],
   "source": [
    "# Using max_depth=5, n_estimators=5, learning_rate=1.0\n",
    "gbrt = GradientBoostingClassifier(max_depth = 5, n_estimators=5, learning_rate=1.0)\n",
    "#Evaluating the model using 10-fold CV with the scoring as accuracy\n",
    "result5 = model_selection.cross_val_score(gbrt, X, y, cv=10, scoring=\"accuracy\")\n",
    "print(\"Accuracy:\", result5.mean())\n",
    "#accuracy is 0.8563\n",
    "#accuracy with max_depth = 5 --> 0.861\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8607232466228474\n"
     ]
    }
   ],
   "source": [
    "# Using max_depth=5, n_estimators=5, learning_rate=0.5\n",
    "gbrt = GradientBoostingClassifier(max_depth = 5, n_estimators=5, learning_rate=0.5)\n",
    "#Evaluating the model using 10-fold CV with the scoring as accuracy\n",
    "result6 = model_selection.cross_val_score(gbrt, X, y, cv=10, scoring=\"accuracy\")\n",
    "print(\"Accuracy:\", result6.mean())\n",
    "#accuracy is 0.856\n",
    "#accuracy with max_depth = 5 --> 0.8607\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7591904489970196\n"
     ]
    }
   ],
   "source": [
    "# Using n_estimators=5, learning_rate=0.0001 \n",
    "gbrt = GradientBoostingClassifier(max_depth = 5,n_estimators=5, learning_rate=0.0001)\n",
    "#Evaluating the model using 10-fold CV with the scoring as accuracy\n",
    "result7 = model_selection.cross_val_score(gbrt, X, y, cv=10, scoring=\"accuracy\")\n",
    "print(\"Accuracy:\", result7.mean())\n",
    "#accuracy is 0.759\n",
    "#accuracy with max_depth = 5 --> 0.759"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "ceterus paribus, lowering the learning_rate lowers the accuracy. You can also see that \n",
    "including max_depth as 5 increases the accuracy of each model in which it previously \n",
    "was not stated and it also increases between models as learning rate increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now changing values for n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8485921553199723\n"
     ]
    }
   ],
   "source": [
    "# Using n_estimators=1, learning_rate=1.0\n",
    "gbrt = GradientBoostingClassifier(max_depth = 5, n_estimators=1, learning_rate=1.0)\n",
    "#Evaluating the model using 10-fold CV with the scoring as accuracy\n",
    "result8 = model_selection.cross_val_score(gbrt, X, y, cv=10, scoring=\"accuracy\")\n",
    "print(\"Accuracy:\", result8.mean())\n",
    "#accuracy is 0.844\n",
    "#accuracy with max_depth = 5 --> 0.849\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8634257418721649\n"
     ]
    }
   ],
   "source": [
    "# Using n_estimators=10, learning_rate=1.0\n",
    "gbrt = GradientBoostingClassifier(max_depth = 5, n_estimators=10, learning_rate=1.0)\n",
    "#Evaluating the model using 10-fold CV with the scoring as accuracy\n",
    "result9 = model_selection.cross_val_score(gbrt, X, y, cv=10, scoring=\"accuracy\")\n",
    "print(\"Accuracy:\", result9.mean())\n",
    "#accuracy is 0.862\n",
    "#accuracy with max_depth = 5 --> 0.863\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.857774683369556\n"
     ]
    }
   ],
   "source": [
    "# Using n_estimators=50, learning_rate=1.0\n",
    "gbrt = GradientBoostingClassifier(max_depth = 5, n_estimators=50, learning_rate=1.0)\n",
    "#Evaluating the model using 10-fold CV with the scoring as accuracy\n",
    "result10 = model_selection.cross_val_score(gbrt, X, y, cv=10, scoring=\"accuracy\")\n",
    "print(\"Accuracy:\", result10.mean())\n",
    "#accuracy is 0.868\n",
    "#accuracy with max_depth = 5 --> 0.858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8530145522891915\n"
     ]
    }
   ],
   "source": [
    "# Using n_estimators=100, learning_rate=1.0\n",
    "gbrt = GradientBoostingClassifier(max_depth = 5, n_estimators=100, learning_rate=1.0)\n",
    "#Evaluating the model using 10-fold CV with the scoring as accuracy\n",
    "result11 = model_selection.cross_val_score(gbrt, X, y, cv=10, scoring=\"accuracy\")\n",
    "print(\"Accuracy:\", result11.mean())\n",
    "#accuracy is 0.864\n",
    "#accuracy with max_depth = 5 --> 0.853"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis \n",
    "In the case of changing the value of n_estimators, it appears that, ceterus paribus, \n",
    "as n_estimators increases so does accuracy but it also looks like it reaches a point\n",
    "where accuracy starts decreasing since the model with n_estimators=50 is higher \n",
    "than the model with n_estimators=100. We also see here that as you increase \n",
    "n_estimators, limiting max_depth to 5 appears to lower the accuracy, which is the \n",
    "opposite of what was occuring with a low n_estimators and any value for learning_rate.\n",
    "Next step here will be to try high values n_estimators with low values of learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing n_estimators and learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7591904489970196\n"
     ]
    }
   ],
   "source": [
    "# Using n_estimators=100, learning_rate=0.0001\n",
    "gbrt = GradientBoostingClassifier(max_depth = 5, n_estimators=100, learning_rate=0.0001)\n",
    "#Evaluating the model using 10-fold CV with the scoring as accuracy\n",
    "result12 = model_selection.cross_val_score(gbrt, X, y, cv=10, scoring=\"accuracy\")\n",
    "print(\"Accuracy:\", result12.mean())\n",
    "#accuracy is 0.759\n",
    "#accuracy with max_depth = 5 --> 0.759"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "here we can see that a large value for n_estimators and a really small learning_rate\n",
    "reduces the accuray by almost 0.10 compared to the same n_estimators with a 1.0 \n",
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
